{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e904cebd-2d63-4d7f-a818-89606ab86eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\asus\\anaconda3\\envs\\datascience\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\asus\\anaconda3\\envs\\datascience\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eec14bc-baa6-4ec4-8ca7-4e4125807435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729f1503-6954-4163-b6b4-4008f6012c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = pd.read_csv(\"dfnew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16c99d86-6f5c-4ba6-b1e1-b96a178da8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpob = pd.read_excel(\"población.xlsm\")\n",
    "dfpob.drop([\"Total Nacional\", \"Nacional\", \"Nacional.1\"], axis = 1, inplace = True)\n",
    "dfpob.drop(dfpob.columns[0], axis = 1, inplace = True)\n",
    "dfpob.to_csv(\"población.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02e694",
   "metadata": {},
   "source": [
    "Este código lee datos desde un archivo Excel \"población.xlsm\" y los carga en un DataFrame llamado dfpob. Luego elimina las columnas llamadas \"Total Nacional\", \"Nacional\" y \"Nacional.1\" utilizando el método drop() con axis=1 para especificar columnas y inplace=True para realizar los cambios en el DataFrame original. Además, elimina la primera columna del DataFrame utilizando dfpob.columns[0] para obtener el nombre de la primera columna y drop() para eliminarla. También guarda un data frame en un archivo .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13165bbb-5c22-46c1-ba83-53e41af91545",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Provincias###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7fc77dc-2426-450d-a061-3631cff7df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preparar dataframes:\n",
    "frecuencia = dfnew[\"provincia\"].value_counts().reset_index()\n",
    "df1 = frecuencia.rename(columns={\"index\": \"Elemento\", \"Elemento\": \"Frecuencia\"})\n",
    "df1 = df1.sort_values(by = \"provincia\")\n",
    "df1.drop(24, inplace = True)\n",
    "df1.rename(columns={\"count\": \"Frecuencia reportes\"}, inplace = True)\n",
    "\n",
    "dfprov = dfpob.drop_duplicates(subset = [\"Total Nacional.1\"])\n",
    "dfprov = dfprov.drop(columns = [\"Nacional.2\", \"Nacional.3\"])\n",
    "dfprov = dfprov.sort_values(by = \"Total Nacional.1\")\n",
    "dfprov.rename(columns = {\"16938986\": \"Población\", \"Total Nacional.1\": \"Provincia\"}, inplace = True)\n",
    "dfprov[\"Provincia\"] = dfprov[\"Provincia\"].str.upper()\n",
    "dfprov[\"Provincia\"] = df1[\"provincia\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59621a",
   "metadata": {},
   "source": [
    " Este código calcula la frecuencia de valores en la columna \"provincia\" del DataFrame dfnew y crea un nuevo DataFrame llamado df1 que contiene dos columnas: \"Elemento\" (los nombres de las provincias) y \"Frecuencia\" (la frecuencia de aparición de cada provincia). Luego se renombran las columnas y se elimina la fila con el índice 24.\n",
    "\n",
    "  Tambien el código manipula el DataFrame dfpob, eliminando duplicados basados en la columna \"Total Nacional.1\", eliminando columnas no deseadas, ordenando el DataFrame por la columna \"Total Nacional.1\" y renombrando columnas. \n",
    "  \n",
    "  Luego, convierte los nombres de provincia en mayúsculas y asigna los valores de provincia del DataFrame df1 a la columna \"Provincia\" del DataFrame dfprov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f516d29-9986-45a0-883e-3eeda258c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Crear nuevo data frame con 4 columnas (Provincia, población, count, frecuencia percápita):\n",
    "df1.reset_index(drop = True, inplace = True)\n",
    "dfprov.reset_index(drop = True, inplace = True)\n",
    "\n",
    "dfprovincial = pd.concat([df1[[\"provincia\"]], dfprov[[\"Población\"]], df1[[\"Frecuencia reportes\"]]], axis = 1)\n",
    "dfprovincial[\"Frecuencia percápita\"] = dfprovincial[\"Frecuencia reportes\"] / dfprovincial[\"Población\"]\n",
    "dfprovincial\n",
    "dfprovincial.to_csv(\"Frec_prov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a515b",
   "metadata": {},
   "source": [
    "Estos códigos reinician los índices de los DataFrames df1 y dfprov para que comiencen desde cero y eliminen los índices anteriores.\n",
    "Crea un nuevo DataFrame llamado dfprovincial combinando las columnas \"provincia\" de df1, \"Población\" de dfprov y \"Frecuencia reportes\" de df1.\n",
    "\n",
    "Tambien calcula la frecuencia per cápita dividiendo la columna \"Frecuencia reportes\" por la columna \"Población\" en el DataFrame dfprovincial.\n",
    "\n",
    "Guarda el DataFrame dfprovincial en un archivo CSV llamado \"Frec_prov.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f73862-0eac-4d42-ace8-46bc932b0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Cantones###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c383097e-6157-4ebf-95f9-70131d048afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preparar dataframes:\n",
    "frecuencia = dfnew[\"Canton\"].value_counts().reset_index()\n",
    "df2 = frecuencia.rename(columns={\"index\": \"Elemento\", \"Elemento\": \"Frecuencia\"})\n",
    "\n",
    "\n",
    "df2.rename(columns={\"count\": \"Frecuencia reportes\"}, inplace = True)\n",
    "df2 = df2.loc[~df2[\"Canton\"].str.contains(\"EL PIEDRERO\")]\n",
    "df2 = df2.loc[~df2[\"Canton\"].str.contains(\"LAS GOLONDRINAS\")]\n",
    "df2 = df2.sort_values(by = \"Canton\")\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "df2.loc[60, \"Canton\"] = \"EL EMPALME\"\n",
    "df2 = df2.sort_values(by = \"Canton\")\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "df2.loc[120, \"Canton\"] = \"FRANCISCO DE ORELLANA\"\n",
    "df2 = df2.sort_values(by = \"Canton\")\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "df2.to_csv(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d9dcf",
   "metadata": {},
   "source": [
    " Este código calcula la frecuencia de valores en la columna \"Canton\" del DataFrame dfnew y crea un nuevo DataFrame llamado df2 que contiene dos columnas: \"Elemento\" (los nombres de los cantones) y \"Frecuencia\" (la frecuencia de aparición de cada cantón).\n",
    "\n",
    "Renombra la columna \"count\" a \"Frecuencia reportes\" en el DataFrame df2. Luego filtra las filas que contienen los cantones \"EL PIEDRERO\" y \"LAS GOLONDRINAS\" utilizando loc con ~ para negar la condición. Después, modifica los nombres de los cantones \"EL EMPALME\" y \"FRANCISCO DE ORELLANA\" en las filas 60 y 120, respectivamente, utilizando loc. Finalmente, ordena el DataFrame df2 por la columna \"Canton\" y reinicia el índice.\n",
    "\n",
    " Guarda el DataFrame df2 en un archivo CSV llamado \"df2.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ba8f962-a42d-4d0a-ac7d-7dfc96507514",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preparar dataframes:\n",
    "dfcan = dfpob.drop_duplicates(subset = [\"Nacional.2\"])\n",
    "dfcan = dfcan.drop(columns = [\"Total Nacional.1\", \"Nacional.3\"])\n",
    "dfcan.rename(columns = {\"16938986\": \"Población\", \"Nacional.2\": \"Cantón\"}, inplace = True)\n",
    "dfcan[\"Cantón\"] = dfcan[\"Cantón\"].str.upper()\n",
    "dfcan.reset_index(drop = True, inplace = True)\n",
    "mascara = ~dfcan[\"Cantón\"].str.contains(\"TOTAL\", na = False)\n",
    "dfcan = dfcan[mascara]\n",
    "dfcan.loc[191, \"Cantón\"] = \"QUITO\"\n",
    "dfcan = dfcan.sort_values(by = \"Cantón\")\n",
    "dfcan.reset_index(drop = True, inplace = True)\n",
    "dfcan.loc[43, \"Cantón\"] = \"CRNEL. MARCELINO MARIDUEÑA\"\n",
    "dfcan = dfcan.sort_values(by = \"Cantón\")\n",
    "dfcan.reset_index(drop = True, inplace = True)\n",
    "dfcan.loc[66, \"Cantón\"] = \"GNRAL. ANTONIO ELIZALDE\"\n",
    "dfcan = dfcan.sort_values(by = \"Cantón\")\n",
    "dfcan.reset_index(drop = True, inplace = True)\n",
    "dfcan.to_csv(\"dfcan.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dc1f8",
   "metadata": {},
   "source": [
    " Este código crea un nuevo DataFrame llamado dfcan utilizando el DataFrame dfpob. Elimina las filas duplicadas basadas en la columna \"Nacional.2\" y elimina las columnas \"Total Nacional.1\" y \"Nacional.3\". Luego, renombra la columna \"16938986\" a \"Población\" y la columna \"Nacional.2\" a \"Cantón\". También convierte los nombres de los cantones a mayúsculas y reinicia el índice del DataFrame\n",
    "\n",
    " Crea una máscara para filtrar las filas donde el nombre del cantón no contiene \"TOTAL\". Luego, modifica manualmente algunos nombres de cantones específicos utilizando loc. Finalmente, reinicia el índice del DataFrame.\n",
    "\n",
    "El código guarda el DataFrame dfcan en un archivo CSV llamado \"dfcan.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46196f32-5139-49a7-9862-71c697edd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Comprobar si los nombres de los cantones están alineados:\n",
    "canton_df2 = df2[\"Canton\"]\n",
    "canton_dfcan = dfcan[\"Cantón\"]\n",
    "\n",
    "df_comprobar_canton = pd.concat([canton_df2, canton_dfcan], axis = 1)\n",
    "df_comprobar_canton.to_csv(\"df_comprobar_canton.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957339f",
   "metadata": {},
   "source": [
    "Estos códigos crean dos Series de pandas, canton_df2 y canton_dfcan, que contienen los nombres de los cantones extraídos de los DataFrames df2 y dfcan, respectivamente.\n",
    "\n",
    " Combina las dos Series canton_df2 y canton_dfcan en un nuevo DataFrame llamado df_comprobar_canton, utilizando el método concat() de pandas con axis=1 para concatenar a lo largo de las columnas.\n",
    "\n",
    " Este código guarda el DataFrame df_comprobar_canton en un archivo CSV llamado \"df_comprobar_canton.csv\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fa3a05f-4808-4784-a315-01c4c8995256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear el df con las frecuencias relativas:\n",
    "dfcanton = pd.concat([df2, dfcan], axis=1)\n",
    "dfcanton = dfcanton.drop(\"Cantón\", axis=1)\n",
    "dfcanton.to_csv(\"dfcanton.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c596db",
   "metadata": {},
   "source": [
    "Este código combina horizontalmente los DataFrames df2 y dfcan en uno nuevo llamado dfcanton, utilizando el método concat() de pandas con axis=1 para concatenar a lo largo de las columnas.\n",
    "\n",
    "Elimina la columna \"Cantón\" del DataFrame dfcanton utilizando el método drop() de pandas con axis=1 para especificar que se trata de una columna.\n",
    "\n",
    "Guarda el DataFrame dfcanton en un archivo CSV llamado \"dfcanton.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a7e1298-7c17-45c1-95dd-a17b26dc3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Crear nuevo data frame con 4 columnas (Canton, población, count, frecuencia percápita):\n",
    "dfcanton[\"Frecuencia percápita\"] = dfcanton[\"Frecuencia reportes\"] / dfcanton[\"Población\"]\n",
    "dfcanton.to_csv(\"Frec_canton.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790fc41a",
   "metadata": {},
   "source": [
    "Este código calcula la frecuencia per cápita dividiendo la columna \"Frecuencia reportes\" por la columna \"Población\" en el DataFrame dfcanton y asigna el resultado a una nueva columna llamada \"Frecuencia percápita\"\n",
    "\n",
    "Agrega una nueva columna al DataFrame dfcanton con la frecuencia per cápita calculada y luego guarda el DataFrame resultante en un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2ec7522-89ef-4bdf-82b6-bf88686ce869",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parroquias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6456224-5e24-468a-ac9a-abb985d214ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preparar dataframes:\n",
    "frecuencia = dfnew[\"Parroquia\"].value_counts().reset_index()\n",
    "df3 = frecuencia.rename(columns={\"index\": \"Elemento\", \"Elemento\": \"Frecuencia\"})\n",
    "df3.rename(columns={\"count\": \"Frecuencia reportes\"}, inplace = True)\n",
    "df3 = df3.sort_values(by = \"Parroquia\")\n",
    "df3.reset_index(drop = True, inplace = True)\n",
    "df3.to_csv(\"df3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e77c2f",
   "metadata": {},
   "source": [
    "Se calcula la frecuencia de valores en la columna \"Parroquia\" del DataFrame dfnew utilizando el método value_counts(), que devuelve una Serie con los valores únicos y sus frecuencias.\n",
    "Luego, se reinician los índices del DataFrame resultante utilizando el método reset_index(), lo que convierte los índices en columnas y crea nuevos índices numéricos.\n",
    "\n",
    "Se renombran las columnas \"index\" y \"Elemento\" a \"Elemento\" y \"Frecuencia\", respectivamente, utilizando el método rename().\n",
    "\n",
    "La columna \"count\" se renombra como \"Frecuencia reportes\" utilizando el método rename() nuevamente.\n",
    "Se ordena el DataFrame alfabéticamente por la columna \"Parroquia\" utilizando el método sort_values().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6842e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preparar dataframes:\n",
    "dfparr = dfpob.drop_duplicates(subset = [\"Nacional.3\"])\n",
    "dfparr = dfparr.drop(columns = [\"Total Nacional.1\", \"Nacional.2\"])\n",
    "dfparr.rename(columns = {\"16938986\": \"Población\", \"Nacional.3\": \"Parroquia\"}, inplace = True)\n",
    "dfparr[\"Parroquia\"] = dfparr[\"Parroquia\"].str.upper()\n",
    "dfparr.reset_index(drop = True, inplace = True)\n",
    "mascara = ~dfparr[\"Parroquia\"].str.contains(\"TOTAL\", na = False)\n",
    "dfparr = dfparr[mascara]\n",
    "dfparr = dfparr.sort_values(by = \"Parroquia\")\n",
    "dfparr.reset_index(drop = True, inplace = True)\n",
    "dfparr.rename(columns = {\"Parroquia\": \"Parroquia2\"}, inplace = True)\n",
    "dfparr.to_csv(\"dfparr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ee28b9",
   "metadata": {},
   "source": [
    "Se crea un nuevo DataFrame llamado dfparr a partir del DataFrame dfpob.\n",
    "Se eliminan las filas duplicadas basadas en la columna \"Nacional.3\".\n",
    "Se eliminan las columnas \"Total Nacional.1\" y \"Nacional.2\".\n",
    "Se renombra la columna \"16938986\" a \"Población\" y la columna \"Nacional.3\" a \"Parroquia\".\n",
    "Los nombres de las parroquias se convierten a mayúsculas.\n",
    "Se reinicia el índice del DataFrame.\n",
    "\n",
    "Se crea una máscara para filtrar las filas donde el nombre de la parroquia no contiene \"TOTAL\".\n",
    "El DataFrame se filtra utilizando la máscara.\n",
    "Se ordena el DataFrame alfabéticamente por la columna \"Parroquia\".\n",
    "Se reinicia el índice del DataFrame.\n",
    "Se renombra la columna \"Parroquia\" a \"Parroquia2\".\n",
    "\n",
    "El DataFrame resultante se guarda en un archivo CSV llamado \"dfparr.csv\" utilizando el método to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a13ee0ad-0ef4-4da9-80c6-ab190a0df782",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Comprobar si los nombres de las parroquias están alineados:\n",
    "parroquia_df3 = df3[\"Parroquia\"]\n",
    "parroquia_dfparr = dfparr[\"Parroquia2\"]\n",
    "df_comprobar_parroquia = pd.concat([parroquia_df3, parroquia_dfparr], axis = 1)\n",
    "df_comprobar_parroquia.to_csv(\"df_comprobar_parroquia.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1a1ba",
   "metadata": {},
   "source": [
    "Estos códigos crean dos series de pandas, parroquia_df3 y parroquia_dfparr, que contienen los nombres de las parroquias extraídos de los DataFrames df3 y dfparr, respectivamente.\n",
    "\n",
    "Tambien combina horizontalmente las dos series parroquia_df3 y parroquia_dfparr en un nuevo DataFrame llamado df_comprobar_parroquia, utilizando el método concat() de pandas con axis=1 para concatenar a lo largo de las columnas.\n",
    "\n",
    "Guarda el DataFrame df_comprobar_parroquia en un archivo CSV llamado \"df_comprobar_parroquia.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c21fcd4-8e7c-4170-80aa-ff8f1cae0ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dado que los datos de población no poseen todas las parroquias que posee la base de datos del ECU911, se considera solo las parroquias que se conoce los datos de la población'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Dado que los datos de población no poseen todas las parroquias que posee la base de datos del ECU911, se considera solo las parroquias que se conoce los datos de la población\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1d2deb9-c1fe-4b29-98d3-9fc9461f8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columnas con los primeros 5 caracteres\n",
    "df3['Clave1'] = df3['Parroquia'].str[:6]\n",
    "dfparr['Clave2'] = dfparr['Parroquia2'].str[:6]\n",
    "\n",
    "# Filtrar el DataFrame original donde las claves coinciden\n",
    "df_unido = pd.merge(df3, dfparr, left_on='Clave1', right_on='Clave2')\n",
    "\n",
    "df_unido = df_unido.drop_duplicates(subset = [\"Parroquia2\"])\n",
    "df_unido = df_unido.drop_duplicates(subset = [\"Parroquia\"])\n",
    "\n",
    "\n",
    "df_unido.to_csv(\"df_unido.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a8db",
   "metadata": {},
   "source": [
    "Este código crea dos nuevas columnas en los DataFrames df3 y dfparr, llamadas \"Clave1\" y \"Clave2\", respectivamente, que contienen los primeros 6 caracteres de los nombres de las parroquias.\n",
    "\n",
    "Fusiona los DataFrames df3 y dfparr utilizando las columnas \"Clave1\" y \"Clave2\". Luego, elimina las filas duplicadas basadas en las columnas \"Parroquia2\" y \"Parroquia\".\n",
    "\n",
    "Usa el DataFrame df_unido en un archivo CSV llamado \"df_unido.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2724848-4509-443e-82fa-e8c341ac57eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Texto1_clean', 'Clean1'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Crear df de las frecuencias relativas de las parroquias:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dfparroquia \u001b[38;5;241m=\u001b[39m df_unido\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClave1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexto1_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParroquia2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClave2\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m dfparroquia\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdfparroquia.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Usfq/lib/python3.11/site-packages/pandas/core/frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5433\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5569\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5570\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5571\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5572\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5573\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5574\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5575\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5576\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Usfq/lib/python3.11/site-packages/pandas/core/generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4785\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Usfq/lib/python3.11/site-packages/pandas/core/generic.py:4827\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4825\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4827\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4828\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4830\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Usfq/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Texto1_clean', 'Clean1'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## Crear df de las frecuencias relativas de las parroquias:\n",
    "dfparroquia = df_unido.drop([\"Clave1\", \"Texto1_clean\", \"Clean1\", \"Parroquia2\", \"Clave2\"], axis = 1)\n",
    "dfparroquia.to_csv(\"dfparroquia.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a6896",
   "metadata": {},
   "source": [
    "Este código elimina las columnas \"Clave1\", \"Texto1_clean\", \"Clean1\", \"Parroquia2\" y \"Clave2\" del DataFrame df_unido utilizando el método drop() de pandas con axis=1 para especificar que se trata de columnas\n",
    "\n",
    "Tambien guarda el DataFrame dfparroquia (que ahora contiene solo las columnas restantes después de la eliminación) en un archivo CSV llamado \"dfparroquia.csv\" utilizando el método to_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "961de612-6654-4863-8fed-30b92217656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Crear nuevo data frame con 4 columnas (Canton, población, count, frecuencia percápita):\n",
    "dfparroquia[\"Frecuencia percápita\"] = dfparroquia[\"Frecuencia reportes\"] / dfparroquia[\"Población\"]\n",
    "dfparroquia.to_csv(\"Frec_parroquia.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9fc9e",
   "metadata": {},
   "source": [
    "Este código calcula la frecuencia per cápita dividiendo la columna \"Frecuencia reportes\" por la columna \"Población\" en el DataFrame dfparroquia y asigna el resultado a una nueva columna llamada \"Frecuencia percápita\"\n",
    "\n",
    "Tambien guarda el DataFrame dfparroquia (que ahora incluye la columna \"Frecuencia percápita\") en un archivo CSV llamado \"Frec_parroquia.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b036fb2b-8796-416b-8743-e4da2f0c49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Preparar datos para el treemap###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a5f09c78-7ef1-4327-b66f-3d328805dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por provincia, cantón, parroquia, servicio y subtipo, y contar cada grupo\n",
    "df_agregado = dfnew.groupby(['provincia', 'Canton', 'Parroquia', 'Servicio', 'Subtipo']).size().reset_index(name='Reportes')\n",
    "df_agregado.head()\n",
    "df_agregado.to_csv(\"df_agregado.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3559964",
   "metadata": {},
   "source": [
    "Este código agrupa el DataFrame dfnew por las columnas 'provincia', 'Canton', 'Parroquia', 'Servicio' y 'Subtipo', luego calcula el tamaño de cada grupo (es decir, cuenta el número de filas en cada grupo) y restablece el índice. El resultado se almacena en un nuevo DataFrame llamado df_agregado, con la columna resultante renombrada como 'Reportes'.\n",
    "\n",
    "Tambien guarda el DataFrame df_agregado en un archivo CSV llamado \"df_agregado.csv\" utilizando el método to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198ebab-937f-466c-aa8d-4ab9fe06166d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
